{"version":3,"file":"static/js/9206.181005f6.chunk.js","mappings":"2OAIA,MAAMA,EAAe,UAErB,SAASC,EAAYC,EAAaC,GAChC,MAAMC,EAASF,EAAOG,UAAUF,GAC1BG,EAAe,SAAHC,OAAYJ,GAC9BD,EAAOG,UAAUF,GAAc,WAI7B,OAHMG,KAAgBE,OACpBA,KAAKF,GAAgBF,EAAOK,KAAKD,OAE5BA,KAAKF,EACd,CACF,CAEA,MAAMI,EAAS,CAAC,IAAK,IAAK,IAAK,KAGzBC,EAAe,GACrB,IAAK,IAAIC,EAAI,EAAGA,EAAI,IAAKA,IACvBD,EAAaE,KACXH,EAAQE,GAAK,EAAK,GAChBF,EAAQE,GAAK,EAAK,GAClBF,EAAQE,GAAK,EAAK,GAClBF,EAAW,EAAJE,IAKb,MAAME,EAAqBH,EAAaI,KAAIC,GAASA,EAAMC,gBAE7C,MAAOC,EAWnBC,WAAAA,CAAAC,GAMC,IANW,WACVC,EAAU,KACVC,GAIDF,EACC,GAAIC,EACFb,KAAKa,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIC,MAAM,kCAFhBf,KAAKa,WAAa,IAAIG,EAAAA,UAAUF,E,CAIlCd,KAAKiB,iBAAcC,CACrB,CAEA,gBAAMC,CAAWC,GACf,MAAMC,SAAgBrB,KAAKsB,eAAeF,GAC1C,IAAKC,EACH,MAAM,IAAIN,MAAM,UAADhB,OAAWqB,EAAI,eAEhC,OAAOC,CACT,CAEA,uBAAME,GACJ,MAAMC,QAAYxB,KAAKa,WAAWY,KAAKC,EAAOC,YAAY,GAAI,EAAG,EAAG,IAC9D,OAAEC,GAAWJ,EACnB,GAAII,EAAOC,YAAY,KAAOrC,EAC5BQ,KAAKiB,aAAc,EACnBjB,KAAK8B,QAAUF,EAAOC,YAAY,OAC7B,IAAID,EAAOG,YAAY,KAAOvC,EAInC,MAAM,IAAIuB,MAAM,mBAHhBf,KAAKiB,aAAc,EACnBjB,KAAK8B,QAAUF,EAAOG,YAAY,E,CAItC,CAOA,iBAAMT,SACEtB,KAAKuB,oBAEX,MAAMS,EAAYhC,KAAKiB,YAAc,MAAQ,SACvCgB,EAAOjC,KAAKiB,YAAc,KAAO,KAEvC,IAAIiB,GAAmB,IAAIC,EAAAA,GACxBH,UAAUA,GACVI,MAAM,cACNC,OAAO,OAAQ,CAAEC,OAAQ,eAE1BJ,EADmB,IAAjBlC,KAAK8B,QACYI,EAAiBN,OAAO,cAAe,CACxDU,OAAQ,IAGSJ,EAAiBK,OAAO,UAkB7C,MAAO,CACLC,QAhBa,IAAIL,EAAAA,GAChBH,UAAUA,GACVS,MAAM,QAAS,CACdC,OAASC,GAAoB,YAANA,IAExBF,MAAM,UAAW,CAEhBC,OAASE,GAAoB,IAANA,GAAiB,IAANA,IAEnCL,OAAO,gBAAiB,CAEvBG,OAASE,GAAcA,GAAK,IAE7BL,OAAO,YAIRM,OAAO,IAAIV,EAAAA,GACRH,UAAUA,GACVO,OAAO,iBACPA,OAAO,YACPO,MAAM,QAAS,CACdR,OAAQ,gBACRS,KAAMb,IAEVc,SAAS,IAAIb,EAAAA,GACVH,UAAUA,GACVO,OAAO,WACPA,OAAO,eACVU,SAAS,IAAId,EAAAA,GACVH,UAAUA,GACVO,OAAO,eACPO,MAAM,eAAgB,CACrBR,OAAQ,cACRS,KAAM,SAAFhD,OAAWkC,KAEhBa,MAAM,cAAe,CACpBR,OAAQ,cACRS,KAAM,SAAFhD,OAAWkC,KAEhBM,OAAO,kBACVW,SAAS,IAAIf,EAAAA,GACVH,UAAUA,GACVO,OAAO,kBACPO,MAAM,kBAAmB,CACxBR,OAAQ,iBACRS,KAAM,SAAFhD,OAAWkC,KAEhBa,MAAM,iBAAkB,CACvBR,OAAQ,iBACRS,KAAM,SAAFhD,OAAWkC,KAEhBQ,MAAM,YAGb,CAOA,eAAMU,SACEnD,KAAKuB,oBAEX,MAAM,OAAEK,SAAiB5B,KAAKa,WAAWY,KACvCC,EAAOC,YAAY,IACnB,EACA,GACA,GAGF,aAD2B3B,KAAKmB,WAAW,WACvBiC,MAAMxB,GAAQyB,MACpC,CAMA,cAAMC,GACJ,MACMC,EACJ,SAFmBvD,KAAKmD,aAEbK,eAAiB,KAA4B,IAAjBxD,KAAK8B,QAAgB,EAAI,KAC5D,OAAEF,SAAiB5B,KAAKa,WAAWY,KACvCC,EAAOC,YAAY4B,GACnB,EACAA,EACA,GAGIE,SADoBzD,KAAKmB,WAAW,UACZiC,MAAMxB,GAAQyB,OAAOR,MAC7CA,EAAQ,CAAC,EAoBf,OAnBqB,IAAjB7C,KAAK8B,QACP2B,EAAUC,SACRC,IAAiE,IAAhE,KAAEvC,EAAI,YAAEwC,GAAoDD,EAC3D,MAAME,EAAOC,IAAAA,UAAeF,GAAa,GAAO5D,KAAKiB,aACrD,GAAI4C,EAAKE,YAAYC,OAAOC,kBAC1B,MAAM,IAAIlD,MACR,qHAGJ8B,EAAMzB,GAAQyC,EAAKK,UAAU,IAIjCT,EAAUC,SACRS,IAAuD,IAAtD,KAAE/C,EAAI,OAAEgD,GAA0CD,EACjDtB,EAAMzB,GAAQgD,CAAM,IAInBvB,CACT,CAKA,sBAAMwB,GACJ,MAAMxB,QAAc7C,KAAKsD,WACzB,OAAOgB,OAAOC,KAAK1B,EACrB,CAKA,sBAAM2B,GACJ,MAAM3B,QAAc7C,KAAKsD,WACnBmB,EAAWH,OAAOC,KAAK1B,GACvB6B,EAAeJ,OAAOK,OAAO9B,GAAOtC,KAAI6D,GAC5CpE,KAAK4E,iBAAiBR,KAElBS,QAAcC,QAAQC,IAAIL,GAC1BM,EAAe,CAAC,EACtB,IAAK,IAAI5E,EAAI,EAAGA,EAAIqE,EAASnC,OAAQlC,GAAK,EACxC4E,EAAaP,EAASrE,IAAMyE,EAAMzE,GAEpC,OAAO4E,CACT,CAMA,qBAAMC,CAAgBC,GACpB,MACMd,SADcpE,KAAKsD,YACJ4B,GACrB,GAAKd,EAGL,OAAOpE,KAAK4E,iBAAiBR,EAC/B,CAEA,sBAAMQ,CAAiBR,GAErB,QAAelD,IAAXkD,GAAwBA,EAAS,EACnC,MAAM,IAAIrD,MAAM,kBAGlB,aADmBf,KAAKmF,WAAWf,EAAQ,EAAG,YAClCgB,OACd,CAEA,wBAAMC,CAAmBjB,GAEvB,QAAelD,IAAXkD,GAAwBA,EAAS,EACnC,MAAM,IAAIrD,MAAM,kBAElB,MAAMuE,QAAatF,KAAKmF,WAAWf,EAAQ,EAAG,WACxCmB,EAAoC,EAAnBD,EAAKE,YAAkB,EACxCC,QAAazF,KAAKmF,WAAWf,EAAS,EAAGmB,EAAgB,WACzDG,EAAuC,EAAtBD,EAAKE,eAAqB,EAC3CC,QAAa5F,KAAKmF,WACtBf,EAAS,EAAImB,EAAiB,EAC9BG,EACA,WASF,MANY,CACVN,QAASE,EAAKF,QACdS,QAAS,CAAEC,OAAQL,EAAKM,aAAclB,MAAOY,EAAKO,aAClDC,WAAY,CAAEH,OAAQF,EAAKM,gBAAiBrB,MAAOe,EAAKO,gBACxDC,YAAahC,EAAS,EAAImB,EAAiB,EAAIG,EAGnD,CAEA,gBAAMP,CAAWf,EAAgB9B,EAAgB+D,GAC/C,MAAM,OAAEzE,SAAiB5B,KAAKa,WAAWY,KACvCC,EAAOC,YAAYW,GACnB,EACAA,EACA8B,GAGF,aADqBpE,KAAKmB,WAAWkF,IACvBjD,MAAMxB,GAAQyB,MAC9B,CAQA,iBAAMiD,CAAYpB,GAAmD,IAAlCqB,EAAWC,UAAAlE,OAAA,QAAApB,IAAAsF,UAAA,GAAAA,UAAA,GAAG,EAAGC,EAAiBD,UAAAlE,OAAA,EAAAkE,UAAA,QAAAtF,EACnE,MACMkD,SADcpE,KAAKsD,YACJ4B,GACrB,IAAKd,EACH,OAGF,MAAMsC,QAAe1G,KAAKqF,mBAAmBjB,GAE7C,GAAImC,EAAc,EAChB,MAAM,IAAII,UAAU,2CAGJzF,IAAduF,GAA2BA,EAAYC,EAAOtB,WAChDqB,EAAYC,EAAOtB,SAGrB,MAAMS,EAAU7F,KAAK4G,sBACnBL,EACAE,EACAC,EAAOb,QAAQC,OACfY,EAAOb,QAAQhB,OAEXoB,EAAajG,KAAK4G,sBACtBL,EACAE,EACAC,EAAOT,WAAWH,OAClBY,EAAOT,WAAWpB,OAGdgC,EAAYnF,EAAOC,YACvBmF,KAAKC,MAAMN,EAAYF,GAAe,GAAK,GAEvCS,EAAkBF,KAAKG,MAAMV,EAAc,IAC3C,OAAE3E,SAAiB5B,KAAKa,WAAWY,KACvCoF,EACA,EACAA,EAAUvE,OACVoE,EAAON,YAAcY,GAGvB,IAAIE,EAAgB,GACpB,IACE,IAAIC,EAAkBZ,EACtBY,EAAkBV,EAClBU,GAAmB,EACnB,CAEA,KAAOlB,EAAW3D,QAAU2D,EAAW,GAAGmB,KAAOD,GAC/ClB,EAAWoB,QAEb,MAAMC,EACJrB,EAAW,IACXA,EAAW,GAAGsB,OAASJ,GACvBlB,EAAW,GAAGmB,IAAMD,EAGtB,GACEtB,EAAQ,IACRsB,GAAmBtB,EAAQ,GAAG0B,OAC9BJ,EAAkBtB,EAAQ,GAAGuB,IAC7B,CACA,MAAMI,EAAgB3B,EAAQwB,QAC9B,KAEEF,EAAkBK,EAAcJ,KAAOD,EAAkBV,EACzDU,GAAmB,EAEnBD,GAAiBI,EAAe,IAAM,IAExCH,GAAmB,C,KACd,CACL,MACMM,EAAcN,EAAkB,EAChCO,EAAO9F,EAFQkF,KAAKG,MAAME,EAAkB,GAAKH,GAGvDE,GAAiBI,EACbhH,EAAmBoH,GAAMD,GACzBtH,EAAauH,GAAMD,E,EAI3B,OAAOP,CACT,CAEAN,qBAAAA,CACEL,EACAE,EACAkB,EACAC,GAGA,IAAIC,EACAC,EACJ,IAAK,IAAI1H,EAAI,EAAGA,EAAIuH,EAAYrF,OAAQlC,GAAK,EAAG,CAC9C,MAAM2H,EAAaJ,EAAYvH,GAE/B,GAAImG,GAAewB,EADDH,EAAWxH,IACgBqG,GAAasB,GAExD,QAAmB7G,IAAf2G,EAA0B,CAC5BC,EAAW1H,EACX,K,YAEsBc,IAAf2G,IACTA,EAAazH,E,CAIjB,QAAmBc,IAAf2G,EACF,MAAO,QAIQ3G,IAAb4G,IACFA,EAAWH,EAAYrF,QAGzB,MAAM0F,EAAS,IAAIC,MAAMH,EAAWD,GACpC,IAAK,IAAIK,EAAWL,EAAYK,EAAWJ,EAAUI,GAAY,EAC/DF,EAAOE,EAAWL,GAAc,CAC9BN,MAAOI,EAAYO,GACnBd,IAAKO,EAAYO,GAAYN,EAAWM,GACxCC,KAAMP,EAAWM,IAGrB,OAAOF,CACT,EAGFvI,EAAYiB,EAAY,eACxBjB,EAAYiB,EAAY,YACxBjB,EAAYiB,EAAY,a,eChbT,MAAM0H,UAAsBC,EAAAA,oBACvC,oBAAMC,GACF,MAAMC,GAAOC,EAAAA,EAAAA,gBAAexI,KAAKyI,OAAQ,sBAIzC,GAAiB,iCAAbF,EAAKG,KAAuD,KAAbH,EAAKG,IAAY,CAChE,MAAMC,GAAOC,EAAAA,EAAAA,cAAaL,EAAMvI,KAAK6I,eAC/BC,QAAaH,EAAKI,SAAS,QACjC,OAAOzE,OAAO0E,YAAqB,OAATF,QAA0B,IAATA,OAAkB,EAASA,EAAKG,MAAM,cAAcC,QAAOC,KAAUA,EAAKC,SAAQ7I,KAAI4I,IAC7H,MAAO/H,EAAMkB,GAAU6G,EAAKF,MAAM,MAClC,MAAO,CAAC7H,GAAOkB,EAAO,IAE9B,CAEJ,CACA3B,WAAAA,CAAY8H,EAAQY,EAAeR,GAC/BS,MAAMb,EAAQY,EAAeR,GAC7B,MAAMU,EAAKvJ,KAAK6I,cAChB7I,KAAKwJ,eAAiBxJ,KAAKsI,iBAC3BtI,KAAKyJ,OAAS,IAAI/I,EAAW,CACzBG,YAAY+H,EAAAA,EAAAA,cAAa5I,KAAK0J,QAAQ,kBAAmBH,IAEjE,CACA,iBAAMI,GACF,MAAMH,QAAuBxJ,KAAKwJ,eAClC,OAAIA,EACOlF,OAAOC,KAAKiF,GAEhBxJ,KAAKyJ,OAAOpF,kBACvB,CACA,gBAAMuF,GACF,MAAMJ,QAAuBxJ,KAAKwJ,eAClC,GAAIA,EACA,OAAOlF,OAAOC,KAAKiF,GAAgBjJ,KAAIsJ,IAAW,CAC9CA,UACAtC,MAAO,EACPH,IAAKoC,EAAeK,OAG5B,MAAMC,QAAiB9J,KAAKyJ,OAAOjF,mBACnC,OAAOF,OAAOC,KAAKuF,GAAUvJ,KAAIsJ,IAAW,CACxCA,UACAtC,MAAO,EACPH,IAAK0C,EAASD,MAEtB,CAMAE,WAAAA,CAAWnJ,GAA0B,IAAzB,QAAEiJ,EAAO,MAAEtC,EAAK,IAAEH,GAAKxG,EAC/B,OAAOoJ,EAAAA,EAAAA,mBAAiBC,UACpB,MAAM9B,QAAanI,KAAKyJ,OAAOxE,gBAAgB4E,GACzCpD,OAAqBvF,IAATiH,EAAqBrB,KAAKoD,IAAI/B,EAAMf,GAAOA,EACvD+C,QAAYnK,KAAKyJ,OAAOnD,YAAYuD,EAAStC,EAAOd,GACtD0D,GACAC,EAASC,KAAK,IAAIC,EAAAA,QAAc,CAC5BC,GAAI,GAAFxK,OAAK8J,EAAO,KAAA9J,OAAIwH,EAAK,KAAAxH,OAAI0G,GAC3BqC,KAAM,CAAEe,UAAStC,QAAOH,IAAKX,EAAW0D,UAGhDC,EAASI,UAAU,GAE3B,CAMAC,aAAAA,GAAmC,E","sources":["../node_modules/@gmod/twobit/src/twoBitFile.ts","../node_modules/@jbrowse/plugin-sequence/esm/TwoBitAdapter/TwoBitAdapter.js"],"sourcesContent":["import Long from 'long'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\nimport { Parser } from '@gmod/binary-parser'\n\nconst TWOBIT_MAGIC = 0x1a412743\n\nfunction tinyMemoize(_class: any, methodName: string) {\n  const method = _class.prototype[methodName]\n  const memoAttrName = `_memo_${methodName}`\n  _class.prototype[methodName] = function _tinyMemoized() {\n    if (!(memoAttrName in this)) {\n      this[memoAttrName] = method.call(this)\n    }\n    return this[memoAttrName]\n  }\n}\n\nconst twoBit = ['T', 'C', 'A', 'G']\n// byteTo4Bases is an array of byteValue -> 'ACTG'\n// the weird `...keys()` incantation generates an array of numbers 0 to 255\nconst byteTo4Bases = [] as string[]\nfor (let i = 0; i < 256; i++) {\n  byteTo4Bases.push(\n    twoBit[(i >> 6) & 3] +\n      twoBit[(i >> 4) & 3] +\n      twoBit[(i >> 2) & 3] +\n      twoBit[i & 3],\n  )\n}\n\ntype ParserName = 'header' | 'index' | 'record1' | 'record2' | 'record3'\nconst maskedByteTo4Bases = byteTo4Bases.map(bases => bases.toLowerCase())\n\nexport default class TwoBitFile {\n  private filehandle: GenericFilehandle\n  private isBigEndian?: boolean\n  private version?: number\n\n  /**\n   * @param {object} args\n   * @param {string} [args.path] filesystem path for the .2bit file to open\n   * @param {Filehandle} [args.filehandle] node fs.promises-like filehandle for the .2bit file.\n   *  Only needs to support `filehandle.read(buffer, offset, length, position)`\n   */\n  constructor({\n    filehandle,\n    path,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new Error('must supply path or filehandle')\n    }\n    this.isBigEndian = undefined\n  }\n\n  async _getParser(name: ParserName) {\n    const parser = (await this._getParsers())[name]\n    if (!parser) {\n      throw new Error(`parser ${name} not found`)\n    }\n    return parser\n  }\n\n  async _detectEndianness() {\n    const ret = await this.filehandle.read(Buffer.allocUnsafe(8), 0, 8, 0)\n    const { buffer } = ret\n    if (buffer.readInt32LE(0) === TWOBIT_MAGIC) {\n      this.isBigEndian = false\n      this.version = buffer.readInt32LE(4)\n    } else if (buffer.readInt32BE(0) === TWOBIT_MAGIC) {\n      this.isBigEndian = true\n      this.version = buffer.readInt32BE(4)\n    } else {\n      throw new Error('not a 2bit file')\n    }\n  }\n\n  // memoize\n  /**\n   * @private\n   * detects the file's endianness and instantiates our binary parsers accordingly\n   */\n  async _getParsers() {\n    await this._detectEndianness()\n\n    const endianess = this.isBigEndian ? 'big' : 'little'\n    const lebe = this.isBigEndian ? 'be' : 'le'\n\n    let indexEntryParser = new Parser()\n      .endianess(endianess)\n      .uint8('nameLength')\n      .string('name', { length: 'nameLength' })\n    if (this.version === 1) {\n      indexEntryParser = indexEntryParser.buffer('offsetBytes', {\n        length: 8,\n      })\n    } else {\n      indexEntryParser = indexEntryParser.uint32('offset')\n    }\n    /* istanbul ignore next */\n    const header = new Parser()\n      .endianess(endianess)\n      .int32('magic', {\n        assert: (m: number) => m === 0x1a412743,\n      })\n      .int32('version', {\n        /* istanbul ignore next */\n        assert: (v: number) => v === 0 || v === 1,\n      })\n      .uint32('sequenceCount', {\n        /* istanbul ignore next */\n        assert: (v: number) => v >= 0,\n      })\n      .uint32('reserved')\n\n    return {\n      header,\n      index: new Parser()\n        .endianess(endianess)\n        .uint32('sequenceCount')\n        .uint32('reserved')\n        .array('index', {\n          length: 'sequenceCount',\n          type: indexEntryParser,\n        }),\n      record1: new Parser()\n        .endianess(endianess)\n        .uint32('dnaSize')\n        .uint32('nBlockCount'),\n      record2: new Parser()\n        .endianess(endianess)\n        .uint32('nBlockCount')\n        .array('nBlockStarts', {\n          length: 'nBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .array('nBlockSizes', {\n          length: 'nBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .uint32('maskBlockCount'),\n      record3: new Parser()\n        .endianess(endianess)\n        .uint32('maskBlockCount')\n        .array('maskBlockStarts', {\n          length: 'maskBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .array('maskBlockSizes', {\n          length: 'maskBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .int32('reserved'),\n      // .buffer('packedDna', { length: 'dnaSize' }),\n    }\n  }\n\n  // memoize\n  /**\n   * @returns {Promise} for object with the file's header information, like\n   *  `{ magic: 0x1a412743, version: 0, sequenceCount: 42, reserved: 0 }`\n   */\n  async getHeader() {\n    await this._detectEndianness()\n\n    const { buffer } = await this.filehandle.read(\n      Buffer.allocUnsafe(16),\n      0,\n      16,\n      0,\n    )\n    const headerParser = await this._getParser('header')\n    return headerParser.parse(buffer).result\n  }\n\n  // memoize\n  /**\n   * @returns {Promise} for object with the file's index of offsets, like `{ seqName: fileOffset, ...}`\n   */\n  async getIndex() {\n    const header = await this.getHeader()\n    const maxIndexLength =\n      8 + header.sequenceCount * (1 + 256 + (this.version === 1 ? 8 : 4))\n    const { buffer } = await this.filehandle.read(\n      Buffer.allocUnsafe(maxIndexLength),\n      0,\n      maxIndexLength,\n      8,\n    )\n    const indexParser = await this._getParser('index')\n    const indexData = indexParser.parse(buffer).result.index\n    const index = {} as { [key: string]: number }\n    if (this.version === 1) {\n      indexData.forEach(\n        ({ name, offsetBytes }: { name: string; offsetBytes: number }) => {\n          const long = Long.fromBytes(offsetBytes, true, !this.isBigEndian)\n          if (long.greaterThan(Number.MAX_SAFE_INTEGER)) {\n            throw new Error(\n              'integer overflow. File offset greater than 2^53-1 encountered. This library can only handle offsets up to 2^53-1.',\n            )\n          }\n          index[name] = long.toNumber()\n        },\n      )\n    } else {\n      indexData.forEach(\n        ({ name, offset }: { name: string; offset: number }) => {\n          index[name] = offset\n        },\n      )\n    }\n    return index\n  }\n\n  /**\n   * @returns {Promise} for an array of string sequence names that are found in the file\n   */\n  async getSequenceNames() {\n    const index = await this.getIndex()\n    return Object.keys(index)\n  }\n\n  /**\n   * @returns {Promise} for an object listing the lengths of all sequences like `{seqName: length, ...}`\n   */\n  async getSequenceSizes() {\n    const index = await this.getIndex()\n    const seqNames = Object.keys(index)\n    const sizePromises = Object.values(index).map(offset =>\n      this._getSequenceSize(offset as number),\n    )\n    const sizes = await Promise.all(sizePromises)\n    const returnObject = {} as { [key: string]: number }\n    for (let i = 0; i < seqNames.length; i += 1) {\n      returnObject[seqNames[i]] = sizes[i]\n    }\n    return returnObject\n  }\n\n  /**\n   * @param {string} seqName name of the sequence\n   * @returns {Promise} for the sequence's length, or undefined if it is not in the file\n   */\n  async getSequenceSize(seqName: string) {\n    const index = await this.getIndex()\n    const offset = index[seqName]\n    if (!offset) {\n      return undefined\n    }\n    return this._getSequenceSize(offset)\n  }\n\n  async _getSequenceSize(offset: number) {\n    // we have to parse the sequence record in 3 parts, because we have to buffer 3 fixed-length file reads\n    if (offset === undefined || offset < 0) {\n      throw new Error('invalid offset')\n    }\n    const rec1 = await this._parseItem(offset, 8, 'record1')\n    return rec1.dnaSize\n  }\n\n  async _getSequenceRecord(offset: number) {\n    // we have to parse the sequence record in 3 parts, because we have to buffer 3 fixed-length file reads\n    if (offset === undefined || offset < 0) {\n      throw new Error('invalid offset')\n    }\n    const rec1 = await this._parseItem(offset, 8, 'record1')\n    const rec2DataLength = rec1.nBlockCount * 8 + 8\n    const rec2 = await this._parseItem(offset + 4, rec2DataLength, 'record2')\n    const rec3DataLength = rec2.maskBlockCount * 8 + 8\n    const rec3 = await this._parseItem(\n      offset + 4 + rec2DataLength - 4,\n      rec3DataLength,\n      'record3',\n    )\n\n    const rec = {\n      dnaSize: rec1.dnaSize,\n      nBlocks: { starts: rec2.nBlockStarts, sizes: rec2.nBlockSizes },\n      maskBlocks: { starts: rec3.maskBlockStarts, sizes: rec3.maskBlockSizes },\n      dnaPosition: offset + 4 + rec2DataLength - 4 + rec3DataLength,\n    }\n    return rec\n  }\n\n  async _parseItem(offset: number, length: number, parserName: ParserName) {\n    const { buffer } = await this.filehandle.read(\n      Buffer.allocUnsafe(length),\n      0,\n      length,\n      offset,\n    )\n    const parser = await this._getParser(parserName)\n    return parser.parse(buffer).result\n  }\n\n  /**\n   * @param {string} seqName name of the sequence you want\n   * @param {number} [regionStart] optional 0-based half-open start of the sequence region to fetch.\n   * @param {number} [regionEnd] optional 0-based half-open end of the sequence region to fetch. defaults to end of the sequence\n   * @returns {Promise} for a string of sequence bases\n   */\n  async getSequence(seqName: string, regionStart = 0, regionEnd: number) {\n    const index = await this.getIndex()\n    const offset = index[seqName]\n    if (!offset) {\n      return undefined\n    }\n    // fetch the record for the seq\n    const record = await this._getSequenceRecord(offset)\n\n    if (regionStart < 0) {\n      throw new TypeError('regionStart cannot be less than 0')\n    }\n    // end defaults to the end of the sequence\n    if (regionEnd === undefined || regionEnd > record.dnaSize) {\n      regionEnd = record.dnaSize\n    }\n\n    const nBlocks = this._getOverlappingBlocks(\n      regionStart,\n      regionEnd,\n      record.nBlocks.starts,\n      record.nBlocks.sizes,\n    )\n    const maskBlocks = this._getOverlappingBlocks(\n      regionStart,\n      regionEnd,\n      record.maskBlocks.starts,\n      record.maskBlocks.sizes,\n    )\n\n    const baseBytes = Buffer.allocUnsafe(\n      Math.ceil((regionEnd - regionStart) / 4) + 1,\n    )\n    const baseBytesOffset = Math.floor(regionStart / 4)\n    const { buffer } = await this.filehandle.read(\n      baseBytes,\n      0,\n      baseBytes.length,\n      record.dnaPosition + baseBytesOffset,\n    )\n\n    let sequenceBases = ''\n    for (\n      let genomicPosition = regionStart;\n      genomicPosition < regionEnd;\n      genomicPosition += 1\n    ) {\n      // check whether we are currently masked\n      while (maskBlocks.length && maskBlocks[0].end <= genomicPosition) {\n        maskBlocks.shift()\n      }\n      const baseIsMasked =\n        maskBlocks[0] &&\n        maskBlocks[0].start <= genomicPosition &&\n        maskBlocks[0].end > genomicPosition\n\n      // process the N block if we have one\n      if (\n        nBlocks[0] &&\n        genomicPosition >= nBlocks[0].start &&\n        genomicPosition < nBlocks[0].end\n      ) {\n        const currentNBlock = nBlocks.shift()\n        for (\n          ;\n          genomicPosition < currentNBlock.end && genomicPosition < regionEnd;\n          genomicPosition += 1\n        ) {\n          sequenceBases += baseIsMasked ? 'n' : 'N'\n        }\n        genomicPosition -= 1\n      } else {\n        const bytePosition = Math.floor(genomicPosition / 4) - baseBytesOffset\n        const subPosition = genomicPosition % 4\n        const byte = buffer[bytePosition]\n        sequenceBases += baseIsMasked\n          ? maskedByteTo4Bases[byte][subPosition]\n          : byteTo4Bases[byte][subPosition]\n      }\n    }\n\n    return sequenceBases\n  }\n\n  _getOverlappingBlocks(\n    regionStart: number,\n    regionEnd: number,\n    blockStarts: number[],\n    blockSizes: number[],\n  ) {\n    // find the start and end indexes of the blocks that match\n    let startIndex\n    let endIndex\n    for (let i = 0; i < blockStarts.length; i += 1) {\n      const blockStart = blockStarts[i]\n      const blockSize = blockSizes[i]\n      if (regionStart >= blockStart + blockSize || regionEnd <= blockStart) {\n        // block does not overlap the region\n        if (startIndex !== undefined) {\n          endIndex = i\n          break\n        }\n      } else if (startIndex === undefined) {\n        startIndex = i\n      } // block does overlap the region, record this if it is the first\n    }\n\n    if (startIndex === undefined) {\n      return []\n    }\n\n    // now format some block objects to return\n    if (endIndex === undefined) {\n      endIndex = blockStarts.length\n    }\n\n    const blocks = new Array(endIndex - startIndex)\n    for (let blockNum = startIndex; blockNum < endIndex; blockNum += 1) {\n      blocks[blockNum - startIndex] = {\n        start: blockStarts[blockNum],\n        end: blockStarts[blockNum] + blockSizes[blockNum],\n        size: blockSizes[blockNum],\n      }\n    }\n    return blocks\n  }\n}\n\ntinyMemoize(TwoBitFile, '_getParsers')\ntinyMemoize(TwoBitFile, 'getIndex')\ntinyMemoize(TwoBitFile, 'getHeader')\n","import { BaseSequenceAdapter } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { openLocation } from '@jbrowse/core/util/io';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport SimpleFeature from '@jbrowse/core/util/simpleFeature';\nimport { TwoBitFile } from '@gmod/twobit';\nimport { readConfObject } from '@jbrowse/core/configuration';\nexport default class TwoBitAdapter extends BaseSequenceAdapter {\n    async initChromSizes() {\n        const conf = readConfObject(this.config, 'chromSizesLocation');\n        // check against default and empty in case someone makes the field blank in\n        // config editor, may want better way to check \"optional config slots\" in\n        // future\n        if (conf.uri !== '/path/to/default.chrom.sizes' && conf.uri !== '') {\n            const file = openLocation(conf, this.pluginManager);\n            const data = await file.readFile('utf8');\n            return Object.fromEntries(data === null || data === void 0 ? void 0 : data.split(/\\n|\\r\\n|\\r/).filter(line => !!line.trim()).map(line => {\n                const [name, length] = line.split('\\t');\n                return [name, +length];\n            }));\n        }\n        return undefined;\n    }\n    constructor(config, getSubAdapter, pluginManager) {\n        super(config, getSubAdapter, pluginManager);\n        const pm = this.pluginManager;\n        this.chromSizesData = this.initChromSizes();\n        this.twobit = new TwoBitFile({\n            filehandle: openLocation(this.getConf('twoBitLocation'), pm),\n        });\n    }\n    async getRefNames() {\n        const chromSizesData = await this.chromSizesData;\n        if (chromSizesData) {\n            return Object.keys(chromSizesData);\n        }\n        return this.twobit.getSequenceNames();\n    }\n    async getRegions() {\n        const chromSizesData = await this.chromSizesData;\n        if (chromSizesData) {\n            return Object.keys(chromSizesData).map(refName => ({\n                refName,\n                start: 0,\n                end: chromSizesData[refName],\n            }));\n        }\n        const refSizes = await this.twobit.getSequenceSizes();\n        return Object.keys(refSizes).map(refName => ({\n            refName,\n            start: 0,\n            end: refSizes[refName],\n        }));\n    }\n    /**\n     * Fetch features for a certain region\n     * @param param -\n     * @returns Observable of Feature objects in the region\n     */\n    getFeatures({ refName, start, end }) {\n        return ObservableCreate(async (observer) => {\n            const size = await this.twobit.getSequenceSize(refName);\n            const regionEnd = size !== undefined ? Math.min(size, end) : end;\n            const seq = await this.twobit.getSequence(refName, start, regionEnd);\n            if (seq) {\n                observer.next(new SimpleFeature({\n                    id: `${refName} ${start}-${regionEnd}`,\n                    data: { refName, start, end: regionEnd, seq },\n                }));\n            }\n            observer.complete();\n        });\n    }\n    /**\n     * called to provide a hint that data tied to a certain region\n     * will not be needed for the foreseeable future and can be purged\n     * from caches, etc\n     */\n    freeResources( /* { region } */) { }\n}\n"],"names":["TWOBIT_MAGIC","tinyMemoize","_class","methodName","method","prototype","memoAttrName","concat","this","call","twoBit","byteTo4Bases","i","push","maskedByteTo4Bases","map","bases","toLowerCase","TwoBitFile","constructor","_ref","filehandle","path","Error","LocalFile","isBigEndian","undefined","_getParser","name","parser","_getParsers","_detectEndianness","ret","read","Buffer","allocUnsafe","buffer","readInt32LE","version","readInt32BE","endianess","lebe","indexEntryParser","Parser","uint8","string","length","uint32","header","int32","assert","m","v","index","array","type","record1","record2","record3","getHeader","parse","result","getIndex","maxIndexLength","sequenceCount","indexData","forEach","_ref2","offsetBytes","long","Long","greaterThan","Number","MAX_SAFE_INTEGER","toNumber","_ref3","offset","getSequenceNames","Object","keys","getSequenceSizes","seqNames","sizePromises","values","_getSequenceSize","sizes","Promise","all","returnObject","getSequenceSize","seqName","_parseItem","dnaSize","_getSequenceRecord","rec1","rec2DataLength","nBlockCount","rec2","rec3DataLength","maskBlockCount","rec3","nBlocks","starts","nBlockStarts","nBlockSizes","maskBlocks","maskBlockStarts","maskBlockSizes","dnaPosition","parserName","getSequence","regionStart","arguments","regionEnd","record","TypeError","_getOverlappingBlocks","baseBytes","Math","ceil","baseBytesOffset","floor","sequenceBases","genomicPosition","end","shift","baseIsMasked","start","currentNBlock","subPosition","byte","blockStarts","blockSizes","startIndex","endIndex","blockStart","blocks","Array","blockNum","size","TwoBitAdapter","BaseSequenceAdapter","initChromSizes","conf","readConfObject","config","uri","file","openLocation","pluginManager","data","readFile","fromEntries","split","filter","line","trim","getSubAdapter","super","pm","chromSizesData","twobit","getConf","getRefNames","getRegions","refName","refSizes","getFeatures","ObservableCreate","async","min","seq","observer","next","SimpleFeature","id","complete","freeResources"],"sourceRoot":""}